{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9066834d-8772-4fc1-bcd6-8c472ffc506a",
   "metadata": {},
   "source": [
    "# <img src=\"imgs/transcribe.png\" alt=\"Amazon Transcribe\" style=\"width: 70px;\"/> Amazon Transcribe \n",
    "\n",
    "\n",
    "Amazon Transcribe is an automatic speech recognition (ASR) service that makes it easy for developers to add speech-to-text capability to their applications. Using the Amazon Transcribe API, you can analyze audio files stored in Amazon S3 and have the service return a text file of the transcribed speech. You can also send a live audio stream to Amazon Transcribe and receive a stream of transcripts in real time.\n",
    "\n",
    "Amazon Transcribe can be used for lots of common applications, including the transcription of customer service calls and generating subtitles on audio and video content. The service can transcribe audio files stored in common formats, like WAV and MP3, with time stamps for every word so that you can easily locate the audio in the original source by searching for the text. Amazon Transcribe is continually learning and improving to keep pace with the evolution of language.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54d85fe-4b05-4847-88dd-d680c732901c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# How it works\n",
    "Amazon Transcribe converts speech to text. A basic transcription request produces a transcript that contains data about the transcribed content, including confidence scores and timestamps for each word or punctuation mark. For a complete list of features that you can apply to your transcription, refer to the feature summary.\n",
    "\n",
    "Transcription methods can be separated into two main categories:\n",
    "\n",
    "* Batch transcription jobs: Transcribe media files that have been uploaded into an Amazon S3 bucket.\n",
    "\n",
    "* Streaming transcriptions: Transcribe media streams in real time.\n",
    "\n",
    "## Here's a list of the supported file formats by a batch transcribe job\n",
    "\n",
    "![supported format](imgs/transcribe-supported-format.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c13654-6873-40c2-98e1-bcb612605364",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "In this project, we are going to use Amazon Transcribe to create subtitle files for the given movies.\n",
    "Disclaimer: These movies are obtained from the internet archive and it's freely available on the internet. The movies used in this example are:\n",
    "\n",
    "* [Wonderful World 1959](https://archive.org/details/0731_Wonderful_World_19_01_23_00) \n",
    "* [Achievement USA 1955](https://archive.org/details/Achievem1955)\n",
    "* [Adventure of Mr Wonderbird]()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22143152-8aaf-4240-a49e-50aa74874212",
   "metadata": {},
   "source": [
    "## Setting up the boto and sagemaker sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "6f233458-b573-453a-8638-9a39ab0bd801",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "f1d48cb4-3b44-4b64-8cac-570f71356b9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transcribe_client = boto3.client(\"transcribe\")\n",
    "session = sagemaker.Session()\n",
    "default_bucket = session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "4f9913a3-8a51-4e55-9f85-756de85192da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "media_file_s3_input_prefix = \"data/amazon-transcribe/input\"\n",
    "media_file_s3_output_prefix = \"data/amazon-transcribe/output\"\n",
    "\n",
    "def submit_transcribe_job(media_file_s3_uri, \n",
    "                          output_bucket_name, \n",
    "                          output_prefix=\"data/amazon-transcribe/output\", \n",
    "                          media_format=\"mp4\", \n",
    "                          identify_language=True, \n",
    "                          identify_multiple_languages=True):\n",
    "    \n",
    "    media_file_name = media_file_s3_uri.split(\"/\")[-1]\n",
    "    output_name = media_file_name.replace(\" \", \"_\")\n",
    "    transcription_name = f\"{output_name}-{time.time()}\"\n",
    "    \n",
    "    response = transcribe_client.start_transcription_job(\n",
    "    TranscriptionJobName=transcription_name,\n",
    "    MediaFormat=media_format,\n",
    "    Media={\n",
    "        'MediaFileUri': media_file_s3_uri,\n",
    "    },\n",
    "    OutputBucketName=output_bucket_name,\n",
    "    OutputKey=f\"{output_prefix}/{output_name}/\",\n",
    "    IdentifyMultipleLanguages=identify_multiple_languages,\n",
    "    Subtitles={\n",
    "            'Formats': [ 'srt' ],\n",
    "            'OutputStartIndex': 1\n",
    "        },\n",
    "    Settings={\n",
    "        'ShowSpeakerLabels': True,\n",
    "        'MaxSpeakerLabels': 10\n",
    "        }\n",
    "    )\n",
    "    return response\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ba7b47-4c8e-4281-bb5a-b392223458b1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loop through the S3 bucket location and invoke a transcribe job for each media file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "8919885b-532e-4f20-b697-bdef733a6932",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_client = boto3.client(\"s3\")\n",
    "objects = s3_client.list_objects_v2(Bucket=default_bucket, Prefix=media_file_s3_input_prefix)\n",
    "\n",
    "responses = []\n",
    "for obj in objects['Contents']:\n",
    "    key = obj['Key']\n",
    "    base_file_name = os.path.basename(key)\n",
    "    media_format = key.split(\".\")[-1]\n",
    "    input_file = f\"s3://{default_bucket}/{key}\"\n",
    "    response = submit_transcribe_job(media_file_s3_uri=input_file, \n",
    "                                     output_bucket_name=default_bucket, \n",
    "                                     output_prefix=media_file_s3_output_prefix,\n",
    "                                     media_format=media_format)\n",
    "    responses.append(response)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cde2562-9c2e-4d60-ab4e-8513be41f546",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Here we'll loop through all the jobs and monitor the status of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "4c9c0cee-6273-4c77-af34-c8e4e2ff63db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Achievem1955.mp4-1676770842.3578079 completed with status: COMPLETED\n",
      "Job bandicam-2021-02-15.mp4-1676770842.4853857 completed with status: COMPLETED\n",
      "Job Achievem1955.mp4-1676770842.3578079 completed with status: COMPLETED\n",
      "Job bandicam-2021-02-15.mp4-1676770842.4853857 completed with status: COMPLETED\n",
      "Job 0731_Wonderful_World_19_01_23_00_3mb.mp4-1676770842.1546438 completed with status: COMPLETED\n",
      "Job Achievem1955.mp4-1676770842.3578079 completed with status: COMPLETED\n",
      "Job bandicam-2021-02-15.mp4-1676770842.4853857 completed with status: COMPLETED\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    completion_cnt = 0\n",
    "    for response in responses:\n",
    "        job_name = response['TranscriptionJob']['TranscriptionJobName']\n",
    "        job = transcribe_client.get_transcription_job( TranscriptionJobName=job_name)     \n",
    "        job_status = job['TranscriptionJob']['TranscriptionJobStatus']\n",
    "        if job_status in [ 'FAILED', 'COMPLETED' ]:\n",
    "            print(f\"Job {job_name} completed with status: {job_status}\")\n",
    "            completion_cnt +=1\n",
    "    if completion_cnt == len(responses):\n",
    "        break\n",
    "    else:\n",
    "        time.sleep(60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "bb4bb67c-7995-4f42-80b0-6c5506699682",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "os.makedirs(\"output\", exist_ok = True)\n",
    "\n",
    "for response in responses:\n",
    "    job_name = response['TranscriptionJob']['TranscriptionJobName']\n",
    "    transcription_response = transcribe_client.get_transcription_job(\n",
    "        TranscriptionJobName=job_name\n",
    "    ) \n",
    "    subfolder_name = f\"output/{job_name}\"\n",
    "    os.makedirs(subfolder_name, exist_ok = True)\n",
    "    media_s3_uri = transcription_response['TranscriptionJob']['Media']['MediaFileUri']\n",
    "    parsed_media_uri = urlparse(media_s3_uri)\n",
    "    media_bucket = parsed_media_uri.hostname\n",
    "    media_file_key = parsed_media_uri.path[1:]\n",
    "    base_media_filename = parsed_media_uri.path.split(\"/\")[-1]\n",
    "    \n",
    "    transcription_file_uri = transcription_response['TranscriptionJob']['Transcript']['TranscriptFileUri']\n",
    "    subtitle_file_uri = transcription_response['TranscriptionJob']['Subtitles']['SubtitleFileUris'][0]\n",
    "\n",
    "    parsed_transcription_uri = urlparse(transcription_file_uri).path.split(\"/\")\n",
    "    transcription_bucket = parsed_transcription_uri[1]\n",
    "    trascription_s3_key = \"/\".join(parsed_transcription_uri[2:])\n",
    "    base_transcription_filename = parsed_transcription_uri[-1]\n",
    "\n",
    "    parsed_subtitle_uri = urlparse(subtitle_file_uri).path.split(\"/\")\n",
    "    subtitle_bucket = parsed_subtitle_uri[1]\n",
    "    subtitle_s3_key = \"/\".join(parsed_subtitle_uri[2:])\n",
    "    base_subtitle_filename = parsed_subtitle_uri[-1]\n",
    "\n",
    "    s3_client.download_file(media_bucket, media_file_key, f\"{subfolder_name}/{base_media_filename}\")\n",
    "    s3_client.download_file(transcription_bucket, trascription_s3_key, f\"{subfolder_name}/{base_transcription_filename}\")\n",
    "    s3_client.download_file(subtitle_bucket, subtitle_s3_key, f\"{subfolder_name}/{base_subtitle_filename}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "f65e8d43-931e-4470-8c35-7aff85c90543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyring is skipped due to an exception: 'keyring.backends'\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install ffmpeg-python -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54e3d87-984c-4f6b-b945-a439ad7ce651",
   "metadata": {
    "tags": []
   },
   "source": [
    "## To test out the subtitles, let's try to run a video file without subtitles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "da5d746f-9e5d-4ae5-9730-a4e4df4869a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "subfolder_name = \"output/Achievem1955.mp4-1676770842.3578079\"\n",
    "base_media_filename=\"Achievem1955.mp4\"\n",
    "base_subtitle_filename = \"Achievem1955.mp4-1676770842.3578079.srt\"\n",
    "base_transcription_filename = \"Achievem1955.mp4-1676770842.3578079.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "9db868e0-d1ef-466f-b744-e2982a350fde",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <video alt=\"video\" controls>\n",
       "        <source src=output/Achievem1955.mp4-1676770842.3578079/Achievem1955.mp4 type=\"video/mp4\">\n",
       "    </video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "local_media_file = f\"{subfolder_name}/{base_media_filename}\"\n",
    "HTML(f\"\"\"\n",
    "    <video alt=\"video\" controls>\n",
    "        <source src={local_media_file} type=\"video/mp4\">\n",
    "    </video>\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "e8c62354-d0d5-4f36-8048-72a2416049a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 http://security.debian.org/debian-security buster/updates InRelease [34.8 kB]\n",
      "Hit:2 http://deb.debian.org/debian buster InRelease       \u001b[0m\n",
      "Hit:3 http://deb.debian.org/debian buster-updates InRelease\u001b[0m\n",
      "Get:4 http://security.debian.org/debian-security buster/updates/main amd64 Packages [433 kB]\n",
      "Fetched 468 kB in 0s (1255 kB/s)  \u001b[0m\u001b[33m\u001b[33m\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "59 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "ffmpeg is already the newest version (7:4.1.10-0+deb10u1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 59 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!apt update && apt install ffmpeg -y -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "efd15ed1-23ae-4229-96d5-1f683bb60b58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "e2cd53e6-961c-4082-88a4-8b9cd8a36da8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "local_subtitle_file = f\"{subfolder_name}/{base_subtitle_filename}\"\n",
    "local_media_file_no_ext = local_media_file.split(\"/\")[-1].split(\".\")[0]\n",
    "local_file_no_ext = f\"{subfolder_name}/{local_media_file_no_ext}\"\n",
    "local_media_file_ext = local_media_file.split(\".\")[-1]\n",
    "subtitled_media_file = f'{local_file_no_ext}.srt.{local_media_file_ext}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec20fc79-703c-45ed-83d0-58a30c8f9666",
   "metadata": {
    "tags": []
   },
   "source": [
    "## To test the subtitle files, we'll use an open source video processing tool called FFMEG to apply subtitle into the original video file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fc6c8b-7f55-4a12-b1a6-982145593608",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    video = ffmpeg.input(local_media_file)\n",
    "    audio = video.audio\n",
    "    ffmpeg.concat(video.filter(\"subtitles\", local_subtitle_file), audio, v=1, a=1).output(subtitled_media_file).run(capture_stdout=True, capture_stderr=True,  overwrite_output=True)\n",
    "except ffmpeg.Error as e:\n",
    "    print('stdout:', e.stdout.decode('utf8'))\n",
    "    print('stderr:', e.stderr.decode('utf8'))\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702d3429-1c94-40a5-8ecd-7675c7c7cd7d",
   "metadata": {},
   "source": [
    "## Now we'll validate the processed video embedded wit the subtitle file in the previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2275b2d4-b4fc-4480-a1e3-b356bd5affdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "HTML(f\"\"\"\n",
    "    <video alt=\"video\" controls>\n",
    "        <source src={subtitled_media_file} type=\"video/mp4\">\n",
    "    </video>\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca71e6cc-f666-4b7b-8cc0-72cac174d279",
   "metadata": {},
   "source": [
    "## Transcribe Job Output\n",
    "Transcription output is in JSON format. The first part of your transcript contains the transcript itself, in paragraph form, followed by additional data for every word and punctuation mark. The data provided depends on the features you include in your request. \n",
    "\n",
    "* At a minimum, your transcript contains the **start time, end time, and confidence score** for every word. \n",
    "* All batch transcripts are stored in Amazon S3 buckets. \n",
    "\n",
    "Let's examine the transcription output from the job that created the subtitle for the videos we just saw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "d3903d77-bac5-4201-8b86-99091a623ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_transcription_output = f\"{subfolder_name}/{base_transcription_filename}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "3f4b655d-ace2-413d-98cf-b4ec4834bf18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open(local_transcription_output, \"r\") as f:\n",
    "    transcribe_output = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d98a04-71b9-4cc0-ac27-cc4b6bbf8bba",
   "metadata": {
    "tags": []
   },
   "source": [
    "Top level items returned from the transcription job are:\n",
    "\n",
    "* jobName\n",
    "* accountId\n",
    "* results\n",
    "* status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "7fbbade8-2f04-4f97-9658-f627966bf42a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['jobName', 'accountId', 'results', 'status'])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcribe_output.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb2ccfa-d5c6-4ed4-8b00-0d99702a1c31",
   "metadata": {},
   "source": [
    "Let's dive into the results to better understand the structure of the transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "fbf5579e-085c-488f-bd4e-c4a0337c66d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['transcripts', 'speaker_labels', 'items', 'language_codes'])"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcribe_output['results'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0423a8dc-e291-4159-95b1-08c60c6a0527",
   "metadata": {
    "tags": []
   },
   "source": [
    "If **ShowSpeakerLabels** is provided in setting of a Amazon transcribe job, transacribe will identify the speakers and provide partitioning detail for each individual speaker.\n",
    "\n",
    "Here are some of the detail available for each identified speaker:\n",
    "\n",
    "* number of speakers\n",
    "* overall start time and end time for each identified speaker\n",
    "* speaker by individual segment, with timeline that corresponds to each speaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "00c61dde-d2b9-4fc5-bd2d-7660e5ef17b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start_time': '22.41',\n",
       " 'speaker_label': 'spk_0',\n",
       " 'end_time': '30.7',\n",
       " 'items': [{'start_time': '22.41',\n",
       "   'speaker_label': 'spk_0',\n",
       "   'end_time': '22.69'},\n",
       "  {'start_time': '22.69', 'speaker_label': 'spk_0', 'end_time': '22.96'},\n",
       "  {'start_time': '22.96', 'speaker_label': 'spk_0', 'end_time': '23.13'},\n",
       "  {'start_time': '23.13', 'speaker_label': 'spk_0', 'end_time': '23.24'},\n",
       "  {'start_time': '23.25', 'speaker_label': 'spk_0', 'end_time': '23.79'},\n",
       "  {'start_time': '23.79', 'speaker_label': 'spk_0', 'end_time': '24.05'},\n",
       "  {'start_time': '24.05', 'speaker_label': 'spk_0', 'end_time': '24.16'},\n",
       "  {'start_time': '24.16', 'speaker_label': 'spk_0', 'end_time': '24.27'},\n",
       "  {'start_time': '24.27', 'speaker_label': 'spk_0', 'end_time': '25.06'},\n",
       "  {'start_time': '25.44', 'speaker_label': 'spk_0', 'end_time': '25.73'},\n",
       "  {'start_time': '25.74', 'speaker_label': 'spk_0', 'end_time': '25.91'},\n",
       "  {'start_time': '25.91', 'speaker_label': 'spk_0', 'end_time': '26.02'},\n",
       "  {'start_time': '26.02', 'speaker_label': 'spk_0', 'end_time': '26.3'},\n",
       "  {'start_time': '26.3', 'speaker_label': 'spk_0', 'end_time': '26.43'},\n",
       "  {'start_time': '26.44', 'speaker_label': 'spk_0', 'end_time': '26.71'},\n",
       "  {'start_time': '26.71', 'speaker_label': 'spk_0', 'end_time': '27.32'},\n",
       "  {'start_time': '27.33', 'speaker_label': 'spk_0', 'end_time': '27.78'},\n",
       "  {'start_time': '27.78', 'speaker_label': 'spk_0', 'end_time': '27.91'},\n",
       "  {'start_time': '27.91', 'speaker_label': 'spk_0', 'end_time': '28.71'},\n",
       "  {'start_time': '28.92', 'speaker_label': 'spk_0', 'end_time': '29.29'},\n",
       "  {'start_time': '29.29', 'speaker_label': 'spk_0', 'end_time': '29.36'},\n",
       "  {'start_time': '29.36', 'speaker_label': 'spk_0', 'end_time': '29.79'},\n",
       "  {'start_time': '29.79', 'speaker_label': 'spk_0', 'end_time': '30.18'},\n",
       "  {'start_time': '30.18', 'speaker_label': 'spk_0', 'end_time': '30.53'}]}"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing a segment of a speaker\n",
    "transcribe_output['results']['speaker_labels']['segments'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9655184-17d6-42db-b128-9d927d8d7e18",
   "metadata": {},
   "source": [
    "The output also returns the entire transcription for each channel. Here's the transcription output from the video that we just watched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "91e29eee-c9fa-414a-b2d4-dc5f7b858f0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It looks like an ordinary day in the USA. But in the city of flint michigan all is excitement, Even a small fryer buzzing and the older boys and girls are let out of school. Oh, this is a day! The whole town's a bustle. Yes, siree. There's going to be a parade too. And what's a parade without festive budding and gala decorations and vans? So the boys with the tall Chicos practice their structure and all over town. The final touches are put on sleek and shiny floats for this parade is going to be a mile long and some of the out of town floats have to be hustled over the road to make it on time. And in the town auditorium, a troop of broadway and Hollywood artists feverishly polished their song and dance routines, symbolizing the teamwork and progress of GM people everywhere for their show is to be played to a standout audience of very important guests, hundreds of guests, many of whom will arrive in flint on a train pulled by a glistening diesel. A golden engine for a golden day. Yes sir, There's excitement from coast to coast on this day everywhere. General Motors people are at work for today in the U. S. A. The entire GM family is playing host with open house at every plant for this is a special day, a once in a lifetime day, a day of achievement for the whole USA for on this day, General Motors is building its 50 millionth car. No one has ever come close to that before. So no wonder celebration is in the very air. The bunting and decorations are up. The floats are almost ready. The red carpets around the signs of welcome are proudly displayed, mothers are bringing the Children to town. For on this day of days, parking is no problem for Buick has provided a stomping ground for the cowboy and diaper centers and Buick's general manager, Ivan Wiles drops in and now on the Chevrolet production line and historic event is about to occur. With some of its millions of predecessors marching before, and the first of more millions following behind, a golden chassis arrives at the body drop mark you Well, this day in american progress for the scurrying clock of history is striking 10. This Tuesday morning of november 23rd 1954. As down from a loft swings the golden body of a car that's been 46 years in the making a car that marks a proud feat of the teamwork of American productive achievement. Unmatched anywhere at any time. The manufacture by the people of one company of 50 million motor cars. This is achievement, achievement by a great nation, by the 160 million free people of that nation. For to the cooperative efforts of the men and women of General Motors working together must be added the work of the countless thousands who supply GM and the countless tens of thousands who supply them. And the thousands of dealers and salesmen and servicemen who sell and care for GM products and the investors who entrust savings and earnings to GM and the millions upon millions of customers whose confidence also has helped make possible this day and this event. So, with pride shared by every GM man and woman everywhere, Chevrolet's general manager, th keating marks the occasion with General Motors president Harlow H. Curtis. Mr Curtis. It is a real honor and a privilege for Chevrolet to produce the 50 millionth car for General Motors. It is a history making achievement and also had an ipod in. Well. Feel very proud. It's a pleasure for me. Mr. Curtis to present to you the key to the 50 millionth car. Thank You very much. Mr Keating. Congratulations. Thank you sir. Men of Chevrolet and Fisher. My sincere congratulations. You have just helped accomplish something that has never been accomplished before. You have produced the 50 millionth car Built by General Motors in the, in the United States since 1908. This is a milestone, unique in the world's industrial history. It was the vision of a bare handful of men here in flint that lost, that launched General Motors in 1908, the automobile. Industry was a struggling infant at that time. In other automobile companies, the same vision existed vision of the automobile, both as an essential means of transportation and as a creator of jobs. The result has been the development of an industry that makes the greatest single count Contribution of any to the strength of the national economy. Over the years, it has constituted a principal source of our country's dynamic growth. The 50 million General Motors car produced in this country stands as a symbol of vision of accomplishment to date. It also is a symbol of progress for the future 50 million cars, so hoist those flags on high, blow those whistles and start that parade. Ah this is a day the entire G. M. Line is represented here, glistening new models of the famous five that make automotive history every day. GMC truck and coach with surging power for the wheels of progress, electro motive with the revolutionary power for the wheels of steel that put new life in the old iron horse Fisher body. That's led a parade of beauty from the days of demure. MS 1908 to modern as tomorrow, Miss 1955. U. A. W. C. I. O. Representing more than 300,000 members of the mighty GMT A. C sparkplug as if you couldn't tell and sparky and sludgy who all work together to to make this nation strong. And here's General Motors Institute that helps train men and women to carry on the tradition of achievement and turn step that puts GMS hardware out in front And of course, little did they dream it? Here's the very first GM car, the 1908 Cadillac that started the biggest parade of industrial products in all history. And GM's million, a 1919, Oldsmobile And the five million a Pontiac from way back in 1926. And the 10 million a buick of only three years later, 1929, And the 25 million a. Chevrolet of only yesterday, 1940 Oh, it's a great day, Alright, A salute to Mr and mrs America to all of us. Americans, who as one people have pioneered and protected the way of life. That is the USA who's courage, confidence, and cooperative accomplishments are proudly symbolized here today by this unparalleled achievement that marks a milestone of progress, pointing the way towards still greater things for all of us everywhere to share fire work. The nation's secret was, and though doubters and scoffers said, this is as far as you get GM answered, you ain't seen.\""
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcribe_output['results']['transcripts'][0]['transcript']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e82d5e-5342-4d2f-a8b2-efc54a40f93c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Transcripts\n",
    "For each identified word, the transcribe job returns a time window, identified language (code), speaker label, confident scores and the type of word\n",
    "\n",
    "Let's take a look at the first 5 items returned from the transcription job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "3648e7c8-02cc-4ff3-a669-d11c2206cb76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'start_time': '22.41',\n",
       "  'language_code': 'en-US',\n",
       "  'speaker_label': 'spk_0',\n",
       "  'end_time': '22.69',\n",
       "  'alternatives': [{'confidence': '1.0', 'content': 'It'}],\n",
       "  'type': 'pronunciation'},\n",
       " {'start_time': '22.69',\n",
       "  'language_code': 'en-US',\n",
       "  'speaker_label': 'spk_0',\n",
       "  'end_time': '22.96',\n",
       "  'alternatives': [{'confidence': '1.0', 'content': 'looks'}],\n",
       "  'type': 'pronunciation'},\n",
       " {'start_time': '22.96',\n",
       "  'language_code': 'en-US',\n",
       "  'speaker_label': 'spk_0',\n",
       "  'end_time': '23.13',\n",
       "  'alternatives': [{'confidence': '1.0', 'content': 'like'}],\n",
       "  'type': 'pronunciation'},\n",
       " {'start_time': '23.13',\n",
       "  'language_code': 'en-US',\n",
       "  'speaker_label': 'spk_0',\n",
       "  'end_time': '23.24',\n",
       "  'alternatives': [{'confidence': '1.0', 'content': 'an'}],\n",
       "  'type': 'pronunciation'},\n",
       " {'start_time': '23.25',\n",
       "  'language_code': 'en-US',\n",
       "  'speaker_label': 'spk_0',\n",
       "  'end_time': '23.79',\n",
       "  'alternatives': [{'confidence': '1.0', 'content': 'ordinary'}],\n",
       "  'type': 'pronunciation'}]"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcribe_output['results']['items'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7118aa2b-66dd-47e5-8666-3b17173359b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
