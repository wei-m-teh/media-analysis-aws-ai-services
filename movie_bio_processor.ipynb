{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/bio/trivia10k13test.bio\", \"r\") as f:\n",
    "    data = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_token = \"\"\n",
    "entity_dict = None\n",
    "entities = []\n",
    "sentence = []\n",
    "sentence_start_offset = 0\n",
    "sentence_end_offset = 0\n",
    "has_csv_header = False\n",
    "line_idx = 0\n",
    "for line in data:\n",
    "    stripped_line = line.strip()\n",
    "    if len(stripped_line) == 0:\n",
    "        if entity_dict:\n",
    "            entities.append(entity_dict.copy())\n",
    "#         with open(\"./data/bio/test_document.txt\", \"a\") as f:\n",
    "#             sentence_str = \" \".join(sentence)\n",
    "#             sentence_str = f\"{sentence_str}\\n\"\n",
    "#             f.write(sentence_str)\n",
    "#         with open(\"./data/bio/entitylist.csv\", \"a\", encoding=\"utf-8\") as csv_file:\n",
    "#             csv_writer = csv.writer(csv_file)\n",
    "#             if not has_csv_header:\n",
    "#                 csv_writer.writerow([\"Text\", \"Type\"])\n",
    "#                 has_csv_header = True\n",
    "#             for e in entities:\n",
    "#                 key = next(iter(e))\n",
    "#                 text = \" \".join(e[key])\n",
    "#                 csv_writer.writerow([text, key])\n",
    "\n",
    "# Annotation\n",
    "        with open(\"./data/bio/test_annotation.csv\", \"a\", encoding=\"utf-8\") as csv_file:\n",
    "            csv_writer = csv.writer(csv_file)\n",
    "            if not has_csv_header:\n",
    "                csv_writer.writerow([\"File\", \"Line\", \"Begin Offset\", \"End Offset\", \"Type\"])\n",
    "                has_csv_header = True\n",
    "            for e in entities:\n",
    "                key = next(iter(e))\n",
    "#                 text = \" \".join(e[key])\n",
    "                begin_offset, end_offset = e[key][0], e[key][-1]\n",
    "                csv_writer.writerow([\"test_document.txt\", line_idx, begin_offset, end_offset, key])\n",
    "\n",
    "#         print(f\"sentence: {sentence}\")\n",
    "#         print(f\"entities: {entities}\")\n",
    "        sentence.clear()\n",
    "        entities.clear()\n",
    "        entity_dict = None        \n",
    "        sentence_start_offset = 0\n",
    "        sentence_end_offset = 0\n",
    "        line_idx += 1\n",
    "        continue\n",
    "    token, word = stripped_line.split(\"\\t\")\n",
    "    sentence.append(word)\n",
    "    sentence_end_offset = sentence_start_offset + len(word)\n",
    "    if token.startswith(\"B-\"):\n",
    "        t = token[2:]\n",
    "        if entity_dict:\n",
    "            entities.append(entity_dict.copy())\n",
    "        entity_dict = {}\n",
    "        entity = []\n",
    "#         entity.append(word)\n",
    "#         print(f\"B word is: {word}\")\n",
    "        entity.append(sentence_start_offset)\n",
    "        entity.append(sentence_end_offset - 1)\n",
    "        entity_dict[t] = entity\n",
    "        prev_token = t\n",
    "    else:\n",
    "        if token.startswith(\"I-\"):\n",
    "            t = token[2:]\n",
    "#             entity_dict[t].append(word)\n",
    "            entity_dict[t].append(sentence_start_offset)\n",
    "            entity_dict[t].append(sentence_end_offset - 1)\n",
    "        else:\n",
    "            if entity_dict:\n",
    "                entities.append(entity_dict.copy())\n",
    "                entity_dict = None\n",
    "#     print(f\"word: {word} start: {sentence_start_offset}, end: {sentence_end_offset}\")\n",
    "    sentence_start_offset = sentence_end_offset + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
