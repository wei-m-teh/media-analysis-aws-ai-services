{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Named Entity Recognition\n",
    "\n",
    "Custom entity recognition helps you identify your specific new entity types that are not in the preset generic entity types. This means that you can analyze documents and extract entities like product codes or business-specific entities that fit your particular needs.\n",
    "\n",
    "Building an accurate custom entity recognizer on your own can be a complex process, requiring preparation of large sets of manually annotated training documents and the selection of the right algorithms and parameters for model training. Amazon Comprehend helps to reduce the complexity by providing automatic annotation and model development to create a custom entity recognition model.\n",
    "\n",
    "Creating a custom entity recognition model is a more effective approach than using string matching or regular expressions to extract entities from documents. For example, to extract ENGINEER names in a document, it is difficult to enumerate all possible names. Additionally, without context, it is challenging to distinguish between ENGINEER names and ANALYST names. A custom entity recognition model can learn the context where those names are likely to appear. Additionally, string matching will not detect entities that have typos or follow new naming conventions, while this is possible using a custom model.\n",
    "\n",
    "You have two options for creating a custom model:\n",
    "\n",
    "* Annotations – provide a data set containing annotated entities for model training.\n",
    "* Entity lists (plaintext only) – provide a list of entities and their type label (such as PRODUCT_CODES and a set of unannotated documents containing those entities for model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIT Movie Dataset\n",
    "\n",
    "For our example, we'll use a template named entity recognition as our input data to train a model to recognize movie industry specific entities. \n",
    "The MIT movie dataset is widely used as a benchmark for evaluating the performance of Named Entity Recognization task. The dataset is detailed in the paper:  https://arxiv.org/pdf/2106.01760.pdf\n",
    "Source URL for the dataset can be found: https://groups.csail.mit.edu/sls/downloads/movie/\n",
    "\n",
    "## Highlights\n",
    "\n",
    "* Given there are multiple training and validation files available, in this example, we are going to leverage the **trivia10ktrain.bio** and **trivia10ktest.bio** as the basis of the training validation dataset.\n",
    "* Since the input files are already formatted into bio (https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)), we will use the annotations option for training the custom model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import boto3\n",
    "import time\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "comprehend = boto3.client(\"comprehend\")\n",
    "session = sagemaker.session.Session()\n",
    "default_bucket = session.default_bucket()\n",
    "s3_movie_entities_prefix = \"data/comprehend/movie-ner/entities\"\n",
    "s3_movie_entities_train_upload_prefix = \"data/comprehend/movie-ner/train\"\n",
    "s3_movie_entities_test_upload_prefix = \"data/comprehend/movie-ner/test\"\n",
    "s3_movie_annotation_prefix = \"data/comprehend/movie-ner/annotations\"\n",
    "data_access_role_arn = \"arn:aws:iam::869530972998:role/service-role/AmazonComprehendServiceRole-default\"\n",
    "s3_movie_ner_job_output_prefix = \"data/comprehend/movie-ner/job-output\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the train annotation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_list_df = pd.read_csv(\"data/bio/train_annotation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Line</th>\n",
       "      <th>Begin Offset</th>\n",
       "      <th>End Offset</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_document.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>Actor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_document.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>58</td>\n",
       "      <td>Plot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_document.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>74</td>\n",
       "      <td>Opinion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_document.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>100</td>\n",
       "      <td>Plot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_document.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>Actor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 File  Line  Begin Offset  End Offset     Type\n",
       "0  train_document.txt     0             0          12    Actor\n",
       "1  train_document.txt     0            25          58     Plot\n",
       "2  train_document.txt     0            60          74  Opinion\n",
       "3  train_document.txt     0            76         100     Plot\n",
       "4  train_document.txt     1             0          12    Actor"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_list_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_entity_list = entity_list_df['Type'].unique()\n",
    "entity_list_for_training = [ { \"Type\" : x} for x in top_entity_list ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Actor', 'Plot', 'Opinion', 'Award', 'Year', 'Genre', 'Origin',\n",
       "       'Director', 'Soundtrack', 'Relationship', 'Character_Name',\n",
       "       'Quote'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_entity_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Custom Named Entity Recognition Model\n",
    "A custom entity recognizer identifies only the entity types that you include when you train the model. It does not automatically include the preset entity types. If you want to also identify the preset entity types,such as LOCATION, DATE, or PERSON, you need to provide additional training data for those entities.\n",
    "\n",
    "When you create a custom entity recognizer using annotated PDF files, you can use the recognizer with a variety of input file formats: plaintext, image files (JPG, PNG, TIFF), PDF files, and Word documents, with no pre-processing or doc flattening required. Amazon Comprehend doesn't support annotation of image files or Word documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client(\"s3\")\n",
    "with open(os.path.join('data/bio/train_document.txt'), \"rb\") as f:\n",
    "    s3.upload_fileobj(f, default_bucket, os.path.join(s3_movie_entities_train_upload_prefix, \"train_document.txt\"))\n",
    "\n",
    "with open(os.path.join('data/bio/test_document.txt'), \"rb\") as f:\n",
    "    s3.upload_fileobj(f, default_bucket, os.path.join(s3_movie_entities_test_upload_prefix, \"test_document.txt\"))\n",
    "    \n",
    "with open(os.path.join('data/bio/train_annotation.csv'), \"rb\") as f:\n",
    "    s3.upload_fileobj(f, default_bucket, os.path.join(s3_movie_annotation_prefix, \"train_annotation.csv\"))\n",
    "\n",
    "with open(os.path.join('data/bio/test_annotation.csv'), \"rb\") as f:\n",
    "    s3.upload_fileobj(f, default_bucket, os.path.join(s3_movie_annotation_prefix, \"test_annotation.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncomment the following block to train a custom entity recognizer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = comprehend.create_entity_recognizer(\n",
    "#     RecognizerName=f\"Movies-NER-{int(time.time())}\",\n",
    "#     LanguageCode=\"en\",\n",
    "#     DataAccessRoleArn=data_access_role_arn,\n",
    "#     InputDataConfig={\n",
    "#         'EntityTypes': entity_list_for_training,\n",
    "#         \"Documents\": {\n",
    "#             \"S3Uri\": f\"s3://{default_bucket}/{s3_movie_entities_train_upload_prefix}\",\n",
    "#             'TestS3Uri': f\"s3://{default_bucket}/{s3_movie_entities_test_upload_prefix}\",\n",
    "#             'InputFormat': 'ONE_DOC_PER_LINE'\n",
    "#         },\n",
    "#         'Annotations': {\n",
    "#             'S3Uri': f\"s3://{default_bucket}/{s3_movie_annotation_prefix}/train_annotation.csv\",\n",
    "#             'TestS3Uri': f\"s3://{default_bucket}/{s3_movie_annotation_prefix}/test_annotation.csv\"\n",
    "#         },\n",
    "#     }\n",
    "# )\n",
    "# recognizer_arn = response[\"EntityRecognizerArn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognizer_arn = \"arn:aws:comprehend:us-east-2:869530972998:entity-recognizer/Movies-NER-1670126643\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    response = comprehend.describe_entity_recognizer(\n",
    "        EntityRecognizerArn=recognizer_arn\n",
    "    )\n",
    "\n",
    "    status = response[\"EntityRecognizerProperties\"][\"Status\"]\n",
    "    if \"IN_ERROR\" == status:\n",
    "        print(\"Job failed\")\n",
    "        break\n",
    "    if \"TRAINED\" == status:\n",
    "        break\n",
    "\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EntityRecognizerProperties': {'EntityRecognizerArn': 'arn:aws:comprehend:us-east-2:869530972998:entity-recognizer/Movies-NER-1670126643', 'LanguageCode': 'en', 'Status': 'TRAINED', 'SubmitTime': datetime.datetime(2022, 12, 4, 4, 4, 3, 458000, tzinfo=tzlocal()), 'EndTime': datetime.datetime(2022, 12, 4, 4, 18, 20, 733000, tzinfo=tzlocal()), 'TrainingStartTime': datetime.datetime(2022, 12, 4, 4, 8, 22, 207000, tzinfo=tzlocal()), 'TrainingEndTime': datetime.datetime(2022, 12, 4, 4, 17, 26, 21000, tzinfo=tzlocal()), 'InputDataConfig': {'DataFormat': 'COMPREHEND_CSV', 'EntityTypes': [{'Type': 'Actor'}, {'Type': 'Plot'}, {'Type': 'Opinion'}, {'Type': 'Award'}, {'Type': 'Year'}, {'Type': 'Genre'}, {'Type': 'Origin'}, {'Type': 'Director'}, {'Type': 'Soundtrack'}, {'Type': 'Relationship'}, {'Type': 'Character_Name'}, {'Type': 'Quote'}], 'Documents': {'S3Uri': 's3://sagemaker-us-east-2-869530972998/data/comprehend/movie-ner/train', 'TestS3Uri': 's3://sagemaker-us-east-2-869530972998/data/comprehend/movie-ner/test', 'InputFormat': 'ONE_DOC_PER_LINE'}, 'Annotations': {'S3Uri': 's3://sagemaker-us-east-2-869530972998/data/comprehend/movie-ner/annotations/train_annotation.csv', 'TestS3Uri': 's3://sagemaker-us-east-2-869530972998/data/comprehend/movie-ner/annotations/test_annotation.csv'}}, 'RecognizerMetadata': {'NumberOfTrainedDocuments': 7052, 'NumberOfTestDocuments': 1953, 'EvaluationMetrics': {'Precision': 63.91442155309033, 'Recall': 70.96603906387472, 'F1Score': 67.25589927457683}, 'EntityTypes': [{'Type': 'Year', 'EvaluationMetrics': {'Precision': 97.59036144578313, 'Recall': 98.03328290468987, 'F1Score': 97.81132075471697}, 'NumberOfTrainMentions': 2461}, {'Type': 'Actor', 'EvaluationMetrics': {'Precision': 88.23970037453184, 'Recall': 92.4646781789639, 'F1Score': 90.3027980068992}, 'NumberOfTrainMentions': 4533}, {'Type': 'Quote', 'EvaluationMetrics': {'Precision': 27.160493827160494, 'Recall': 46.808510638297875, 'F1Score': 34.375}, 'NumberOfTrainMentions': 106}, {'Type': 'Award', 'EvaluationMetrics': {'Precision': 44.871794871794876, 'Recall': 53.03030303030303, 'F1Score': 48.611111111111114}, 'NumberOfTrainMentions': 262}, {'Type': 'Relationship', 'EvaluationMetrics': {'Precision': 47.8494623655914, 'Recall': 52.046783625730995, 'F1Score': 49.85994397759104}, 'NumberOfTrainMentions': 491}, {'Type': 'Plot', 'EvaluationMetrics': {'Precision': 42.22826086956522, 'Recall': 49.36467598475222, 'F1Score': 45.51845342706502}, 'NumberOfTrainMentions': 5836}, {'Type': 'Origin', 'EvaluationMetrics': {'Precision': 24.74576271186441, 'Recall': 38.421052631578945, 'F1Score': 30.103092783505154}, 'NumberOfTrainMentions': 660}, {'Type': 'Character_Name', 'EvaluationMetrics': {'Precision': 53.42465753424658, 'Recall': 55.12367491166078, 'F1Score': 54.2608695652174}, 'NumberOfTrainMentions': 877}, {'Type': 'Genre', 'EvaluationMetrics': {'Precision': 70.86330935251799, 'Recall': 74.90494296577947, 'F1Score': 72.82809611829944}, 'NumberOfTrainMentions': 3068}, {'Type': 'Director', 'EvaluationMetrics': {'Precision': 80.61002178649237, 'Recall': 87.05882352941177, 'F1Score': 83.71040723981899}, 'NumberOfTrainMentions': 1595}, {'Type': 'Opinion', 'EvaluationMetrics': {'Precision': 40.08620689655172, 'Recall': 47.69230769230769, 'F1Score': 43.559718969555036}, 'NumberOfTrainMentions': 684}, {'Type': 'Soundtrack', 'EvaluationMetrics': {'Precision': 7.142857142857142, 'Recall': 12.5, 'F1Score': 9.090909090909092}, 'NumberOfTrainMentions': 32}]}, 'DataAccessRoleArn': 'arn:aws:iam::869530972998:role/service-role/AmazonComprehendServiceRole-default'}, 'ResponseMetadata': {'RequestId': '7ca9f738-5a8d-42b7-b96d-fb1137d79a8e', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '7ca9f738-5a8d-42b7-b96d-fb1137d79a8e', 'content-type': 'application/x-amz-json-1.1', 'content-length': '3186', 'date': 'Tue, 10 Jan 2023 17:57:15 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Describe the entity recognizer job status\n",
    "response = comprehend.describe_entity_recognizer(EntityRecognizerArn=recognizer_arn)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Realtime analysis for the trained custom entity recognizer\n",
    "\n",
    "You can use the Amazon Comprehend run real-time analysis with a custom model. First, you create an endpoint to run the real-time analysis. After you create the endpoint, you run the real-time analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncomment the following block to deploy an endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# endpoint_name = f\"MoviesNER-{int(time.time())}\"\n",
    "# response = comprehend.create_endpoint(\n",
    "#     EndpointName=endpoint_name,\n",
    "#     ModelArn=recognizer_arn,\n",
    "#     DesiredInferenceUnits=10,\n",
    "#     DataAccessRoleArn=data_access_role_arn\n",
    "# )\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_arn = \"arn:aws:comprehend:us-east-2:869530972998:entity-recognizer-endpoint/MoviesNER-1670128101\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = comprehend.detect_entities(\n",
    "    Text='what 2008 disney animated film starred john travolta as the titular dog and miley cyrus as his owner',\n",
    "    LanguageCode='en',\n",
    "    EndpointArn=endpoint_arn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Entities': [{'Score': 0.9999878406524658,\n",
       "   'Type': 'Year',\n",
       "   'Text': '2008',\n",
       "   'BeginOffset': 5,\n",
       "   'EndOffset': 9},\n",
       "  {'Score': 0.5947182774543762,\n",
       "   'Type': 'Genre',\n",
       "   'Text': 'disney animated',\n",
       "   'BeginOffset': 10,\n",
       "   'EndOffset': 25},\n",
       "  {'Score': 0.9999480843544006,\n",
       "   'Type': 'Actor',\n",
       "   'Text': 'john travolta',\n",
       "   'BeginOffset': 39,\n",
       "   'EndOffset': 52},\n",
       "  {'Score': 0.9843842387199402,\n",
       "   'Type': 'Actor',\n",
       "   'Text': 'miley cyrus',\n",
       "   'BeginOffset': 76,\n",
       "   'EndOffset': 87}],\n",
       " 'ResponseMetadata': {'RequestId': 'b3acad40-55b8-4304-bd4d-620b7d6512ed',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'b3acad40-55b8-4304-bd4d-620b7d6512ed',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '398',\n",
       "   'date': 'Tue, 10 Jan 2023 17:57:29 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Custom Entity Recognition Job Asynchronously\n",
    "\n",
    "You can run an asynchronous analysis job to detect custom entities in a set of one or more documents.\n",
    "\n",
    "Before you begin\n",
    "You need a custom entity recognition model (also known as a recognizer) before you can detect custom entities. For more information about these models, see Training custom recognizers.\n",
    "\n",
    "A recognizer that is trained with plain-text annotations supports entity detection for plain-text documents only. A recognizer that is trained with PDF document annotations supports entity detection for plain-text documents, images, PDF files, and Word documents. For files other than text files, Amazon Comprehend performs text extraction before running the analysis. For information about the input files, see Inputs for asynchronous custom analysis.\n",
    "\n",
    "To run an async analysis job, you perform the following overall steps:\n",
    "\n",
    "* Store the documents in an Amazon S3 bucket.\n",
    "* Use the API or console to start the analysis job.\n",
    "* Monitor the progress of the analysis job.\n",
    "* After the job runs to completion, retrieve the results of the analysis from the S3 bucket that you specified when you started the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'JobId': 'fc076550e00c40e04895ee664701af6c', 'JobArn': 'arn:aws:comprehend:us-east-2:869530972998:entities-detection-job/fc076550e00c40e04895ee664701af6c', 'JobStatus': 'SUBMITTED', 'ResponseMetadata': {'RequestId': '31b74b9e-5e06-4bfb-a21a-34cb21db895d', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '31b74b9e-5e06-4bfb-a21a-34cb21db895d', 'content-type': 'application/x-amz-json-1.1', 'content-length': '177', 'date': 'Mon, 05 Dec 2022 18:47:43 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "response = comprehend.start_entities_detection_job(\n",
    "    EntityRecognizerArn=recognizer_arn,\n",
    "    JobName=f\"Movies-NER-{int(time.time())}\",\n",
    "    LanguageCode=\"en\",\n",
    "    DataAccessRoleArn=data_access_role_arn,\n",
    "    InputDataConfig={\n",
    "        \"InputFormat\": \"ONE_DOC_PER_LINE\",\n",
    "        \"S3Uri\": f\"s3://{default_bucket}/{s3_movie_entities_test_upload_prefix}\",\n",
    "        \"InputFormat\" : 'ONE_DOC_PER_LINE'\n",
    "    },\n",
    "    OutputDataConfig={\n",
    "        \"S3Uri\": f\"s3://{default_bucket}/{s3_movie_ner_job_output_prefix}\"\n",
    "    }\n",
    "    \n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_recognition_job_output_df = pd.read_json(\"results/entity_recognition/output\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_recognition_job_output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_recognition_job_output_df['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
